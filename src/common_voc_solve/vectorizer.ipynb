{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_stop_words = ['условия', 'преимущества работы', 'у нас есть', 'предлагаем', 'гарантируем', 'нужно будет']\n",
    "requirements_start_words = ['Требования', 'Твой функционал', 'мы ожидаем', 'хотим от', 'вас', 'тебя', 'нужно знать',\n",
    "                            'нужно уметь', 'Ключевые умения', 'ожидания']\n",
    "\n",
    "def hh_vacancy_requirements_extractor(row):\n",
    "    for start_word in requirements_start_words:\n",
    "        for stop_word in requirements_stop_words:\n",
    "            start_position = row.find(start_word)\n",
    "            stop_position = row.find(stop_word)\n",
    "            if stop_position > start_position:\n",
    "                return row[start_position + len(start_word): stop_position]\n",
    "    return ''\n",
    "\n",
    "skills_mark_words = [('знать', '1 4 объем дисциплины'),\n",
    "                     ('содержание дисциплины', '3 распределение учебного времени')]\n",
    "\n",
    "\n",
    "def extract(doc, mark_sent):\n",
    "    mark_start, mark_end = mark_sent\n",
    "    start_position = doc.find(mark_start)\n",
    "    end_position = doc.find(mark_end)\n",
    "    if start_position == -1 or end_position == -1 or start_position > end_position:\n",
    "        return ''\n",
    "    return doc[start_position + len(mark_start): end_position] + extract(doc[end_position + len(mark_end):], mark_sent)\n",
    "\n",
    "\n",
    "def education_skills_extractor(document):\n",
    "    result = extract(document, skills_mark_words[0])\n",
    "    content = extract(document, skills_mark_words[1])\n",
    "    return ' '.join([result, content])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf для документов hh\n",
    "data_set = pd.read_csv('./merged.csv')\n",
    "documents = data_set['description']\n",
    "term, documents_matrix = matrix.DocumentMatrixBuilder().build_matrix(documents, hh_vacancy_requirements_extractor, min_df=0.001)\n",
    "matrix.save_matrix_and_terms(term, documents_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf для документов обр программ по модулям\n",
    "data_set = pd.read_csv('./ed.csv')\n",
    "name = data_set['name']\n",
    "documents = data_set['documents']\n",
    "\n",
    "term, documents_matrix = matrix.DocumentMatrixBuilder().build_matrix(\n",
    "    documents, education_skills_extractor, min_df=0.005)\n",
    "matrix.save_matrix_and_terms(term, documents_matrix, './ed_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf для документов обр программ по дисцплинам\n",
    "data_set = pd.read_csv('./ed_by_dist.csv')\n",
    "name = data_set['name']\n",
    "documents = data_set['documents']\n",
    "\n",
    "term, documents_matrix = matrix.DocumentMatrixBuilder().build_matrix(\n",
    "    documents, education_skills_extractor, min_df=0.005)\n",
    "matrix.save_matrix_and_terms(term, documents_matrix, './ed_matrix_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vocabulary(_in, _this):\n",
    "    counter = len(_in)\n",
    "    for key in _this.keys():\n",
    "        if key in _in:\n",
    "            continue\n",
    "        _in[key] = counter\n",
    "        counter = counter + 1\n",
    "    return _in\n",
    "\n",
    "def save_vocabulary(voc, file_name):\n",
    "    with open(file_name, 'w', encoding='utf-8') as fd:\n",
    "        for word in voc:\n",
    "            fd.write('{}\\n'.format(word))\n",
    "\n",
    "def get_corpus_and_vocabulary(data, competency_extractor, min_df=0.05, max_df=0.99):\n",
    "    document_matrix_builder = matrix.DocumentMatrixBuilder()\n",
    "    corpus, vocabulary = document_matrix_builder.get_prepocessing_text_and_vocabulary(data, min_df=min_df,\n",
    "                                                                                        max_df=max_df,\n",
    "                                                                                        sub_text_extractor=competency_extractor)\n",
    "    return corpus, vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# общий Tf-Idf для документов обр программ по модулям и hh\n",
    "data_set = pd.read_csv('./merged.csv')\n",
    "hh_vacancy = data_set['description']\n",
    "data_set = pd.read_csv('./ed.csv')\n",
    "educations = data_set['documents']\n",
    "\n",
    "hh_corpus, hh_vocabulary = get_corpus_and_vocabulary(hh_vacancy,hh_vacancy_requirements_extractor, min_df=0.005, max_df=0.99)\n",
    "ed_corpus, ed_vocabulary = get_corpus_and_vocabulary(educations, education_skills_extractor, min_df=0.005,max_df=0.99)\n",
    "save_vocabulary(ed_vocabulary, './ed_voc')\n",
    "\n",
    "\n",
    "merged_vocabulary = merge_vocabulary(hh_vocabulary, ed_vocabulary)\n",
    "\n",
    "hh_vector, hh_terms = matrix.DocumentMatrixBuilder().build_matrix_from_corpus_and_vocabulary(hh_corpus, merged_vocabulary)\n",
    "matrix.save_matrix_and_terms(hh_terms, hh_vector, './com_matrix')\n",
    "\n",
    "ed_vecor, ed_terms = matrix.DocumentMatrixBuilder().build_matrix_from_corpus_and_vocabulary(ed_corpus, merged_vocabulary)\n",
    "matrix.save_matrix_and_terms(ed_terms, ed_vecor, './com_ed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# общий Tf-Idf для документов обр программ по дисциплинам и hh\n",
    "data_set = pd.read_csv('./merged.csv')\n",
    "hh_vacancy = data_set['description']\n",
    "data_set = pd.read_csv('./ed_by_dist.csv')\n",
    "educations = data_set['documents']\n",
    "\n",
    "hh_corpus, hh_vocabulary = get_corpus_and_vocabulary(hh_vacancy,hh_vacancy_requirements_extractor, min_df=0.05, max_df=0.99)\n",
    "ed_corpus, ed_vocabulary = get_corpus_and_vocabulary(educations,education_skills_extractor, min_df=0.005,max_df=0.99)\n",
    "save_vocabulary(ed_vocabulary, './ed_dist_voc')\n",
    "\n",
    "merged_vocabulary = merge_vocabulary(hh_vocabulary, ed_vocabulary)\n",
    "\n",
    "document_matrix_builder = matrix.DocumentMatrixBuilder()\n",
    "hh_vector, hh_terms = document_matrix_builder.build_matrix_from_corpus_and_vocabulary(hh_corpus, merged_vocabulary)\n",
    "matrix.save_matrix_and_terms(hh_terms, hh_vector, './com_matrix_dist')\n",
    "\n",
    "ed_vecor, ed_terms = document_matrix_builder.build_matrix_from_corpus_and_vocabulary(ed_corpus, merged_vocabulary)\n",
    "matrix.save_matrix_and_terms(ed_terms, ed_vecor, './com_ed_dist')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
